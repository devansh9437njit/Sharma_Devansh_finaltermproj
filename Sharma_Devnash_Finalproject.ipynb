{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sharma_Devnash_Finalproject.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBM16M7VJNtd"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7wl_wRdJRCH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c47ce8f-228a-401e-a049-c7ed87f4fc14"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGdChhPpIpps"
      },
      "source": [
        "# **Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Is2jOgZIUkr"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import classification_report,accuracy_score\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn import tree\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from math import sqrt\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D80SWdyoyMRr"
      },
      "source": [
        "# Load **Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3FfsJwPIbye",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "46304ca5-62c9-409e-9837-adfef49ac1fb"
      },
      "source": [
        "data = pd.read_csv(open('/content/drive/My Drive/Colab Notebooks/breast-cancer-dataset.csv','rb'))\n",
        "\n",
        "data.head(7)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_code_number</th>\n",
              "      <th>clump_thickness</th>\n",
              "      <th>uniformity_of_cell_size</th>\n",
              "      <th>uniformity_of_cell_shape</th>\n",
              "      <th>marginal_adhesion</th>\n",
              "      <th>single_epithelial_cell_size</th>\n",
              "      <th>bare_nuclei</th>\n",
              "      <th>bland_chromatin</th>\n",
              "      <th>normal_nucleoli</th>\n",
              "      <th>mitoses</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000025</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1002945</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1015425</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1016277</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1017023</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1017122</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1018099</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sample_code_number  clump_thickness  ...  mitoses  label\n",
              "0             1000025                5  ...        1      2\n",
              "1             1002945                5  ...        1      2\n",
              "2             1015425                3  ...        1      2\n",
              "3             1016277                6  ...        1      2\n",
              "4             1017023                4  ...        1      2\n",
              "5             1017122                8  ...        1      4\n",
              "6             1018099                1  ...        1      2\n",
              "\n",
              "[7 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJsjfml8OKd-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcd2c5c9-66bc-4190-8f06-a60d37b32b72"
      },
      "source": [
        "\n",
        "label=data['label']\n",
        "data=data.drop(['label'],axis=1)\n",
        "label.head(7)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2\n",
              "1    2\n",
              "2    2\n",
              "3    2\n",
              "4    2\n",
              "5    4\n",
              "6    2\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XayWlzqaOj4T"
      },
      "source": [
        "features=data.replace(to_replace =[\"?\"], value =0) \n",
        "features.to_excel(\"features.xlsx\") "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wV2EG92nyzfn"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Vcx56yeTTcQX",
        "outputId": "24de1c06-262f-45e6-e8c7-798ad99fc0c5"
      },
      "source": [
        "important_features=features[['single_epithelial_cell_size', 'bare_nuclei', 'normal_nucleoli', 'mitoses']]\n",
        "important_features.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>single_epithelial_cell_size</th>\n",
              "      <th>bare_nuclei</th>\n",
              "      <th>normal_nucleoli</th>\n",
              "      <th>mitoses</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   single_epithelial_cell_size bare_nuclei  normal_nucleoli  mitoses\n",
              "0                            2           1                1        1\n",
              "1                            7          10                2        1\n",
              "2                            2           2                1        1\n",
              "3                            3           4                7        1\n",
              "4                            2           1                1        1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Psq948eAW6Aj"
      },
      "source": [
        "# **Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWOmkw2RKfV9",
        "outputId": "a747a7c8-a27b-414a-dc08-6a3d25ab8461"
      },
      "source": [
        "from sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold\n",
        "from scipy.stats import uniform, randint\n",
        "random_initializer=100  \n",
        "TP=[]\n",
        "FP=[]\n",
        "TN=[]\n",
        "FN=[]\n",
        "acc=[]\n",
        "kf = StratifiedKFold(n_splits=10,\n",
        "                     shuffle=False,\n",
        "                     random_state=random_initializer)\n",
        "\n",
        "for train_index, test_index in kf.split(important_features,label):\n",
        "    print('Fold------------------------------------ ')\n",
        "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_Train, X_Test = important_features.loc[train_index], important_features.loc[test_index]\n",
        "    Y_Train, Y_Test = label[train_index], label[test_index]\n",
        "    regressor = RandomForestRegressor(n_estimators=1, random_state=43)\n",
        "    regressor.fit(X_Train, Y_Train)\n",
        "    y_pred = regressor.predict(X_Test)\n",
        "    y_pred=np.round(y_pred)\n",
        "    # print('confusion_matrix',confusion_matrix(Y_Test,y_pred))\n",
        "    print('classification_report',classification_report(Y_Test,y_pred))\n",
        "    print('accuracy_score',accuracy_score(Y_Test, y_pred))\n",
        "    CM = confusion_matrix(Y_Test, y_pred)\n",
        "    TN.append(CM[0][0])\n",
        "    FN.append(CM[1][0])\n",
        "    TP.append(CM[1][1])\n",
        "    FP.append(CM[0][1])\n",
        "    acc.append(accuracy_score(Y_Test, y_pred))\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold------------------------------------ \n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           2       0.89      0.89      0.89        46\n",
            "           4       0.79      0.79      0.79        24\n",
            "\n",
            "    accuracy                           0.86        70\n",
            "   macro avg       0.84      0.84      0.84        70\n",
            "weighted avg       0.86      0.86      0.86        70\n",
            "\n",
            "accuracy_score 0.8571428571428571\n",
            "Fold------------------------------------ \n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "         2.0       0.94      0.96      0.95        46\n",
            "         3.0       0.00      0.00      0.00         0\n",
            "         4.0       0.90      0.79      0.84        24\n",
            "\n",
            "    accuracy                           0.90        70\n",
            "   macro avg       0.61      0.58      0.60        70\n",
            "weighted avg       0.93      0.90      0.91        70\n",
            "\n",
            "accuracy_score 0.9\n",
            "Fold------------------------------------ \n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "         2.0       0.96      0.93      0.95        46\n",
            "         3.0       0.00      0.00      0.00         0\n",
            "         4.0       0.88      0.88      0.88        24\n",
            "\n",
            "    accuracy                           0.91        70\n",
            "   macro avg       0.61      0.60      0.61        70\n",
            "weighted avg       0.93      0.91      0.92        70\n",
            "\n",
            "accuracy_score 0.9142857142857143\n",
            "Fold------------------------------------ \n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           2       0.98      0.87      0.92        46\n",
            "           4       0.79      0.96      0.87        24\n",
            "\n",
            "    accuracy                           0.90        70\n",
            "   macro avg       0.88      0.91      0.89        70\n",
            "weighted avg       0.91      0.90      0.90        70\n",
            "\n",
            "accuracy_score 0.9\n",
            "Fold------------------------------------ \n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "         2.0       0.96      0.93      0.95        46\n",
            "         3.0       0.00      0.00      0.00         0\n",
            "         4.0       0.87      0.83      0.85        24\n",
            "\n",
            "    accuracy                           0.90        70\n",
            "   macro avg       0.61      0.59      0.60        70\n",
            "weighted avg       0.93      0.90      0.91        70\n",
            "\n",
            "accuracy_score 0.9\n",
            "Fold------------------------------------ \n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "         2.0       0.93      0.93      0.93        46\n",
            "         3.0       0.00      0.00      0.00         0\n",
            "         4.0       0.91      0.88      0.89        24\n",
            "\n",
            "    accuracy                           0.91        70\n",
            "   macro avg       0.62      0.60      0.61        70\n",
            "weighted avg       0.93      0.91      0.92        70\n",
            "\n",
            "accuracy_score 0.9142857142857143\n",
            "Fold------------------------------------ \n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "         2.0       0.96      0.98      0.97        46\n",
            "         3.0       0.00      0.00      0.00         0\n",
            "         4.0       1.00      0.83      0.91        24\n",
            "\n",
            "    accuracy                           0.93        70\n",
            "   macro avg       0.65      0.60      0.63        70\n",
            "weighted avg       0.97      0.93      0.95        70\n",
            "\n",
            "accuracy_score 0.9285714285714286\n",
            "Fold------------------------------------ \n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "         2.0       0.96      1.00      0.98        46\n",
            "         3.0       0.00      0.00      0.00         0\n",
            "         4.0       1.00      0.88      0.93        24\n",
            "\n",
            "    accuracy                           0.96        70\n",
            "   macro avg       0.65      0.62      0.64        70\n",
            "weighted avg       0.97      0.96      0.96        70\n",
            "\n",
            "accuracy_score 0.9571428571428572\n",
            "Fold------------------------------------ \n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           2       0.90      1.00      0.95        45\n",
            "           4       1.00      0.80      0.89        25\n",
            "\n",
            "    accuracy                           0.93        70\n",
            "   macro avg       0.95      0.90      0.92        70\n",
            "weighted avg       0.94      0.93      0.93        70\n",
            "\n",
            "accuracy_score 0.9285714285714286\n",
            "Fold------------------------------------ \n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           2       0.96      0.96      0.96        45\n",
            "           4       0.92      0.92      0.92        24\n",
            "\n",
            "    accuracy                           0.94        69\n",
            "   macro avg       0.94      0.94      0.94        69\n",
            "weighted avg       0.94      0.94      0.94        69\n",
            "\n",
            "accuracy_score 0.9420289855072463\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YywUAx3IjnW7",
        "outputId": "b27d207a-b7cd-46fb-dfd5-f2fa2a7edbac"
      },
      "source": [
        "    TN,FP,FN,TP=confusion_matrix(Y_Test,y_pred).ravel()\n",
        "    #Sensitivity or true positive rate\n",
        "    TPR = TP/(TP+FN)\n",
        "    print('True positive Rate:', TPR)\n",
        "    # Specificity or true negative rate\n",
        "    TNR = TN/(TN+FP) \n",
        "    print('True Negative Rate:', TNR)\n",
        "\n",
        "    FPR=FP/(FP+TN)\n",
        "    print('False Positive Rate',FPR)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True positive Rate: 0.9166666666666666\n",
            "True Negative Rate: 0.9555555555555556\n",
            "False Positive Rate 0.044444444444444446\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtKqt27DOkNk",
        "outputId": "e470328c-c658-4d95-ae16-ba5610465b50"
      },
      "source": [
        "np.average(acc)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9142028985507246"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTM0EEmZTSGv"
      },
      "source": [
        "# **NaiveBayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpKIZsk2L6fH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65fe0b5f-f0f8-4f3a-8051-eb3e285524bb"
      },
      "source": [
        "from sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold\n",
        "from scipy.stats import uniform, randint\n",
        "random_initializer=100  \n",
        "TP=[]\n",
        "FP=[]\n",
        "TN=[]\n",
        "FN=[]\n",
        "acc=[]\n",
        "kf = StratifiedKFold(n_splits=10,\n",
        "                     shuffle=False,\n",
        "                     random_state=random_initializer)\n",
        "\n",
        "for train_index, test_index in kf.split(important_features,label):\n",
        "    print('Fold------------------------------------ ')\n",
        "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_Train, X_Test = important_features.loc[train_index], important_features.loc[test_index]\n",
        "    Y_Train, Y_Test = label[train_index], label[test_index]\n",
        "    \n",
        "    gnb = GaussianNB()\n",
        "    y_pred = gnb.fit(X_Train, Y_Train).predict(X_Test)\n",
        "    print('confusion_matrix',confusion_matrix(Y_Test,y_pred))\n",
        "    print('classification_report',classification_report(Y_Test,y_pred))\n",
        "    print('accuracy_score',accuracy_score(Y_Test, y_pred))\n",
        "    CM = confusion_matrix(Y_Test, y_pred)\n",
        "    TN.append(CM[0][0])\n",
        "    FN.append(CM[1][0])\n",
        "    TP.append(CM[1][1])\n",
        "    FP.append(CM[0][1])\n",
        "    acc.append(accuracy_score(Y_Test, y_pred))\n",
        "np.mean(acc)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold------------------------------------ \n",
            "confusion_matrix [[41  5]\n",
            " [ 3 21]]\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           2       0.93      0.89      0.91        46\n",
            "           4       0.81      0.88      0.84        24\n",
            "\n",
            "    accuracy                           0.89        70\n",
            "   macro avg       0.87      0.88      0.88        70\n",
            "weighted avg       0.89      0.89      0.89        70\n",
            "\n",
            "accuracy_score 0.8857142857142857\n",
            "Fold------------------------------------ \n",
            "confusion_matrix [[44  2]\n",
            " [ 1 23]]\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           2       0.98      0.96      0.97        46\n",
            "           4       0.92      0.96      0.94        24\n",
            "\n",
            "    accuracy                           0.96        70\n",
            "   macro avg       0.95      0.96      0.95        70\n",
            "weighted avg       0.96      0.96      0.96        70\n",
            "\n",
            "accuracy_score 0.9571428571428572\n",
            "Fold------------------------------------ \n",
            "confusion_matrix [[43  3]\n",
            " [ 0 24]]\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           2       1.00      0.93      0.97        46\n",
            "           4       0.89      1.00      0.94        24\n",
            "\n",
            "    accuracy                           0.96        70\n",
            "   macro avg       0.94      0.97      0.95        70\n",
            "weighted avg       0.96      0.96      0.96        70\n",
            "\n",
            "accuracy_score 0.9571428571428572\n",
            "Fold------------------------------------ \n",
            "confusion_matrix [[40  6]\n",
            " [ 1 23]]\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           2       0.98      0.87      0.92        46\n",
            "           4       0.79      0.96      0.87        24\n",
            "\n",
            "    accuracy                           0.90        70\n",
            "   macro avg       0.88      0.91      0.89        70\n",
            "weighted avg       0.91      0.90      0.90        70\n",
            "\n",
            "accuracy_score 0.9\n",
            "Fold------------------------------------ \n",
            "confusion_matrix [[45  1]\n",
            " [ 0 24]]\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           2       1.00      0.98      0.99        46\n",
            "           4       0.96      1.00      0.98        24\n",
            "\n",
            "    accuracy                           0.99        70\n",
            "   macro avg       0.98      0.99      0.98        70\n",
            "weighted avg       0.99      0.99      0.99        70\n",
            "\n",
            "accuracy_score 0.9857142857142858\n",
            "Fold------------------------------------ \n",
            "confusion_matrix [[44  2]\n",
            " [ 1 23]]\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           2       0.98      0.96      0.97        46\n",
            "           4       0.92      0.96      0.94        24\n",
            "\n",
            "    accuracy                           0.96        70\n",
            "   macro avg       0.95      0.96      0.95        70\n",
            "weighted avg       0.96      0.96      0.96        70\n",
            "\n",
            "accuracy_score 0.9571428571428572\n",
            "Fold------------------------------------ \n",
            "confusion_matrix [[46  0]\n",
            " [ 1 23]]\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           2       0.98      1.00      0.99        46\n",
            "           4       1.00      0.96      0.98        24\n",
            "\n",
            "    accuracy                           0.99        70\n",
            "   macro avg       0.99      0.98      0.98        70\n",
            "weighted avg       0.99      0.99      0.99        70\n",
            "\n",
            "accuracy_score 0.9857142857142858\n",
            "Fold------------------------------------ \n",
            "confusion_matrix [[45  1]\n",
            " [ 0 24]]\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           2       1.00      0.98      0.99        46\n",
            "           4       0.96      1.00      0.98        24\n",
            "\n",
            "    accuracy                           0.99        70\n",
            "   macro avg       0.98      0.99      0.98        70\n",
            "weighted avg       0.99      0.99      0.99        70\n",
            "\n",
            "accuracy_score 0.9857142857142858\n",
            "Fold------------------------------------ \n",
            "confusion_matrix [[45  0]\n",
            " [ 4 21]]\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           2       0.92      1.00      0.96        45\n",
            "           4       1.00      0.84      0.91        25\n",
            "\n",
            "    accuracy                           0.94        70\n",
            "   macro avg       0.96      0.92      0.94        70\n",
            "weighted avg       0.95      0.94      0.94        70\n",
            "\n",
            "accuracy_score 0.9428571428571428\n",
            "Fold------------------------------------ \n",
            "confusion_matrix [[43  2]\n",
            " [ 0 24]]\n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           2       1.00      0.96      0.98        45\n",
            "           4       0.92      1.00      0.96        24\n",
            "\n",
            "    accuracy                           0.97        69\n",
            "   macro avg       0.96      0.98      0.97        69\n",
            "weighted avg       0.97      0.97      0.97        69\n",
            "\n",
            "accuracy_score 0.9710144927536232\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.952815734989648"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN6viZ0HVVL1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cfedf76-8d9e-4e9b-a2aa-5375d566e799"
      },
      "source": [
        "    TN,FP,FN,TP=confusion_matrix(Y_Test,y_pred).ravel()\n",
        "    #Sensitivity or true positive rate\n",
        "    TPR = TP/(TP+FN)\n",
        "    print('True positive Rate:', TPR)\n",
        "    # Specificity or true negative rate\n",
        "    TNR = TN/(TN+FP) \n",
        "    print('True Negative Rate:', TNR)\n",
        "\n",
        "    FPR=FP/(FP+TN)\n",
        "    print('False Positive Rate',FPR)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True positive Rate: 1.0\n",
            "True Negative Rate: 0.9555555555555556\n",
            "False Positive Rate 0.044444444444444446\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fPVyVFsEJGC"
      },
      "source": [
        "# **Decision Tree**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COmG-GMrV6QB",
        "outputId": "cb27b288-0475-4a29-ba0c-7b06caf48faf"
      },
      "source": [
        "from sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold\n",
        "from scipy.stats import uniform, randint\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "random_initializer=100  \n",
        "TP=[]\n",
        "FP=[]\n",
        "TN=[]\n",
        "FN=[]\n",
        "acc=[]\n",
        "kf = StratifiedKFold(n_splits=10,\n",
        "                     shuffle=False,\n",
        "                     random_state=random_initializer)\n",
        "\n",
        "for train_index, test_index in kf.split(important_features,label):\n",
        "    print('Fold------------------------------------ ')\n",
        "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_Train, X_Test = important_features.loc[train_index], important_features.loc[test_index]\n",
        "    Y_Train, Y_Test = label[train_index], label[test_index]\n",
        "    clf = tree.DecisionTreeClassifier()\n",
        "    clf.fit(X_Train, Y_Train)\n",
        "    y_pred = clf.predict(X_Test)\n",
        "    y_pred=np.round(y_pred)\n",
        "    # print('confusion_matrix',confusion_matrix(Y_Test,y_pred))\n",
        "    print('classification_report',classification_report(Y_Test,y_pred))\n",
        "    print('accuracy_score',accuracy_score(Y_Test, y_pred))\n",
        "    CM = confusion_matrix(Y_Test, y_pred)\n",
        "    TN.append(CM[0][0])\n",
        "    FN.append(CM[1][0])\n",
        "    TP.append(CM[1][1])\n",
        "    FP.append(CM[0][1])\n",
        "    acc.append(accuracy_score(Y_Test, y_pred))\n",
        "np.mean(acc)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold------------------------------------ \n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           2       0.90      0.93      0.91        46\n",
            "           4       0.86      0.79      0.83        24\n",
            "\n",
            "    accuracy                           0.89        70\n",
            "   macro avg       0.88      0.86      0.87        70\n",
            "weighted avg       0.88      0.89      0.88        70\n",
            "\n",
            "accuracy_score 0.8857142857142857\n",
            "Fold------------------------------------ \n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           2       0.88      0.98      0.93        46\n",
            "           4       0.95      0.75      0.84        24\n",
            "\n",
            "    accuracy                           0.90        70\n",
            "   macro avg       0.91      0.86      0.88        70\n",
            "weighted avg       0.90      0.90      0.90        70\n",
            "\n",
            "accuracy_score 0.9\n",
            "Fold------------------------------------ \n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           2       0.98      0.96      0.97        46\n",
            "           4       0.92      0.96      0.94        24\n",
            "\n",
            "    accuracy                           0.96        70\n",
            "   macro avg       0.95      0.96      0.95        70\n",
            "weighted avg       0.96      0.96      0.96        70\n",
            "\n",
            "accuracy_score 0.9571428571428572\n",
            "Fold------------------------------------ \n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           2       0.98      0.89      0.93        46\n",
            "           4       0.82      0.96      0.88        24\n",
            "\n",
            "    accuracy                           0.91        70\n",
            "   macro avg       0.90      0.92      0.91        70\n",
            "weighted avg       0.92      0.91      0.92        70\n",
            "\n",
            "accuracy_score 0.9142857142857143\n",
            "Fold------------------------------------ \n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           2       0.98      0.98      0.98        46\n",
            "           4       0.96      0.96      0.96        24\n",
            "\n",
            "    accuracy                           0.97        70\n",
            "   macro avg       0.97      0.97      0.97        70\n",
            "weighted avg       0.97      0.97      0.97        70\n",
            "\n",
            "accuracy_score 0.9714285714285714\n",
            "Fold------------------------------------ \n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           2       0.96      0.96      0.96        46\n",
            "           4       0.92      0.92      0.92        24\n",
            "\n",
            "    accuracy                           0.94        70\n",
            "   macro avg       0.94      0.94      0.94        70\n",
            "weighted avg       0.94      0.94      0.94        70\n",
            "\n",
            "accuracy_score 0.9428571428571428\n",
            "Fold------------------------------------ \n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           2       1.00      1.00      1.00        46\n",
            "           4       1.00      1.00      1.00        24\n",
            "\n",
            "    accuracy                           1.00        70\n",
            "   macro avg       1.00      1.00      1.00        70\n",
            "weighted avg       1.00      1.00      1.00        70\n",
            "\n",
            "accuracy_score 1.0\n",
            "Fold------------------------------------ \n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           2       1.00      1.00      1.00        46\n",
            "           4       1.00      1.00      1.00        24\n",
            "\n",
            "    accuracy                           1.00        70\n",
            "   macro avg       1.00      1.00      1.00        70\n",
            "weighted avg       1.00      1.00      1.00        70\n",
            "\n",
            "accuracy_score 1.0\n",
            "Fold------------------------------------ \n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           2       0.88      1.00      0.94        45\n",
            "           4       1.00      0.76      0.86        25\n",
            "\n",
            "    accuracy                           0.91        70\n",
            "   macro avg       0.94      0.88      0.90        70\n",
            "weighted avg       0.92      0.91      0.91        70\n",
            "\n",
            "accuracy_score 0.9142857142857143\n",
            "Fold------------------------------------ \n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           2       0.96      1.00      0.98        45\n",
            "           4       1.00      0.92      0.96        24\n",
            "\n",
            "    accuracy                           0.97        69\n",
            "   macro avg       0.98      0.96      0.97        69\n",
            "weighted avg       0.97      0.97      0.97        69\n",
            "\n",
            "accuracy_score 0.9710144927536232\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9456728778467909"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0rHkUf8pZ9I",
        "outputId": "173e9ca9-0414-43d0-bb79-4a57a952874e"
      },
      "source": [
        "#Sensitivity or true positive rate\n",
        "TPR = tp/(tp+fn)\n",
        "# Specificity or true negative rate\n",
        "TNR = tn/(tn+fp) \n",
        "print('True Positive Rate:', TPR)\n",
        "print('True Negative Rate:', TNR)\n",
        "\n",
        "FPR=fp/(fp+tn)\n",
        "print('FPR',FPR)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True Positive Rate: 0.7916666666666666\n",
            "True Negative Rate: 0.8913043478260869\n",
            "FPR 0.10869565217391304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhLBsqQRh1vG"
      },
      "source": [
        "# **SVM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3G3z1cvWZkI",
        "outputId": "99d6a796-6933-4007-e131-f315ef29c99c"
      },
      "source": [
        "from sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold\n",
        "from scipy.stats import uniform, randint\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "random_initializer=100  \n",
        "TP=[]\n",
        "FP=[]\n",
        "TN=[]\n",
        "FN=[]\n",
        "acc=[]\n",
        "kf = StratifiedKFold(n_splits=10,\n",
        "                     shuffle=False,\n",
        "                     random_state=random_initializer)\n",
        "\n",
        "for train_index, test_index in kf.split(important_features,label):\n",
        "    print('Fold------------------------------------ ')\n",
        "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_Train, X_Test = important_features.loc[train_index], important_features.loc[test_index]\n",
        "    Y_Train, Y_Test = label[train_index], label[test_index]\n",
        "    clf =  svm.SVC(kernel='rbf',gamma=0.1,C=0.1, degree=2)\n",
        "    clf.fit(X_Train, Y_Train)\n",
        "    y_pred = clf.predict(X_Test)\n",
        "    y_pred=np.round(y_pred)\n",
        "    # print('confusion_matrix',confusion_matrix(Y_Test,y_pred))\n",
        "    print('classification_report',classification_report(Y_Test,y_pred))\n",
        "    print('accuracy_score',accuracy_score(Y_Test, y_pred))\n",
        "    CM = confusion_matrix(Y_Test, y_pred)\n",
        "    TN.append(CM[0][0])\n",
        "    FN.append(CM[1][0])\n",
        "    TP.append(CM[1][1])\n",
        "    FP.append(CM[0][1])\n",
        "    acc.append(accuracy_score(Y_Test, y_pred))\n",
        "np.mean(acc)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold------------------------------------ \n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           2       0.95      0.89      0.92        46\n",
            "           4       0.81      0.92      0.86        24\n",
            "\n",
            "    accuracy                           0.90        70\n",
            "   macro avg       0.88      0.90      0.89        70\n",
            "weighted avg       0.91      0.90      0.90        70\n",
            "\n",
            "accuracy_score 0.9\n",
            "Fold------------------------------------ \n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           2       0.98      0.96      0.97        46\n",
            "           4       0.92      0.96      0.94        24\n",
            "\n",
            "    accuracy                           0.96        70\n",
            "   macro avg       0.95      0.96      0.95        70\n",
            "weighted avg       0.96      0.96      0.96        70\n",
            "\n",
            "accuracy_score 0.9571428571428572\n",
            "Fold------------------------------------ \n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           2       1.00      0.93      0.97        46\n",
            "           4       0.89      1.00      0.94        24\n",
            "\n",
            "    accuracy                           0.96        70\n",
            "   macro avg       0.94      0.97      0.95        70\n",
            "weighted avg       0.96      0.96      0.96        70\n",
            "\n",
            "accuracy_score 0.9571428571428572\n",
            "Fold------------------------------------ \n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           2       0.97      0.83      0.89        46\n",
            "           4       0.74      0.96      0.84        24\n",
            "\n",
            "    accuracy                           0.87        70\n",
            "   macro avg       0.86      0.89      0.87        70\n",
            "weighted avg       0.89      0.87      0.87        70\n",
            "\n",
            "accuracy_score 0.8714285714285714\n",
            "Fold------------------------------------ \n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           2       1.00      0.98      0.99        46\n",
            "           4       0.96      1.00      0.98        24\n",
            "\n",
            "    accuracy                           0.99        70\n",
            "   macro avg       0.98      0.99      0.98        70\n",
            "weighted avg       0.99      0.99      0.99        70\n",
            "\n",
            "accuracy_score 0.9857142857142858\n",
            "Fold------------------------------------ \n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           2       1.00      0.96      0.98        46\n",
            "           4       0.92      1.00      0.96        24\n",
            "\n",
            "    accuracy                           0.97        70\n",
            "   macro avg       0.96      0.98      0.97        70\n",
            "weighted avg       0.97      0.97      0.97        70\n",
            "\n",
            "accuracy_score 0.9714285714285714\n",
            "Fold------------------------------------ \n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           2       1.00      0.98      0.99        46\n",
            "           4       0.96      1.00      0.98        24\n",
            "\n",
            "    accuracy                           0.99        70\n",
            "   macro avg       0.98      0.99      0.98        70\n",
            "weighted avg       0.99      0.99      0.99        70\n",
            "\n",
            "accuracy_score 0.9857142857142858\n",
            "Fold------------------------------------ \n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           2       1.00      0.98      0.99        46\n",
            "           4       0.96      1.00      0.98        24\n",
            "\n",
            "    accuracy                           0.99        70\n",
            "   macro avg       0.98      0.99      0.98        70\n",
            "weighted avg       0.99      0.99      0.99        70\n",
            "\n",
            "accuracy_score 0.9857142857142858\n",
            "Fold------------------------------------ \n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           2       0.96      1.00      0.98        45\n",
            "           4       1.00      0.92      0.96        25\n",
            "\n",
            "    accuracy                           0.97        70\n",
            "   macro avg       0.98      0.96      0.97        70\n",
            "weighted avg       0.97      0.97      0.97        70\n",
            "\n",
            "accuracy_score 0.9714285714285714\n",
            "Fold------------------------------------ \n",
            "classification_report               precision    recall  f1-score   support\n",
            "\n",
            "           2       1.00      0.96      0.98        45\n",
            "           4       0.92      1.00      0.96        24\n",
            "\n",
            "    accuracy                           0.97        69\n",
            "   macro avg       0.96      0.98      0.97        69\n",
            "weighted avg       0.97      0.97      0.97        69\n",
            "\n",
            "accuracy_score 0.9710144927536232\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9556728778467909"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tV_FFMbqp-gP",
        "outputId": "27d606ce-9cc0-4713-b8bd-811030286544"
      },
      "source": [
        "#Sensitivity or true positive rate\n",
        "TPR = tp/(tp+fn)\n",
        "# Specificity or true negative rate\n",
        "TNR = tn/(tn+fp) \n",
        "print('True Positive Rate:', TPR)\n",
        "print('True Negative Rate:', TNR)\n",
        "\n",
        "FPR=fp/(fp+tn)\n",
        "print('FPR',FPR)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True Positive Rate: 0.7916666666666666\n",
            "True Negative Rate: 0.8913043478260869\n",
            "FPR 0.10869565217391304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFoOZCXWWCRE"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# **Plot**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "BZq3nMiEIccI",
        "outputId": "11a6ee09-c371-45d4-804a-caae419b8c8b"
      },
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "  \n",
        "# defining labels\n",
        "Models = ['RF', 'NB', 'DT', 'SVM']\n",
        "  \n",
        "# portion covered by each label\n",
        "slices = [0.94, 0.98,0.97, 0.96]\n",
        "  \n",
        "# color for each label\n",
        "colors = ['r', 'y', 'g', 'b']\n",
        "  \n",
        "# plotting the pie chart\n",
        "plt.pie(slices, labels = Models, colors=colors, \n",
        "        startangle=90, shadow = True, explode = (0, 0, 0.1, 0),\n",
        "        radius = 1.2, autopct = '%1.1f%%')\n",
        "  \n",
        "# plotting legend\n",
        "plt.legend()\n",
        "  \n",
        "# showing the plot\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}